{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64c4dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import random\n",
    "import os\n",
    "from camoufox.async_api import AsyncCamoufox\n",
    "from camoufox import DefaultAddons\n",
    "from playwright_captcha import ClickSolver, FrameworkType, CaptchaType\n",
    "import datetime\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5849cf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def handle_cookies(page):\n",
    "\n",
    "    print('Checking for cookies on the page...')\n",
    "\n",
    "    try:\n",
    "        accept_button = page.get_by_role(\"button\", name=re.compile(\"Accept\", re.IGNORECASE))\n",
    "        if await accept_button.is_visible(timeout=5000):\n",
    "            print(\"Accepting cookies\")\n",
    "            await accept_button.click()\n",
    "            await asyncio.sleep(2)\n",
    "    except Exception:\n",
    "        print(\"No cookies found\")\n",
    "\n",
    "def save_to_json(data, filename=\"tripadvisor_data.json\"):\n",
    "    existing_data = []\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                existing_data = json.load(f)\n",
    "            except (json.JSONDecodeError, ValueError):\n",
    "                existing_data = []\n",
    "    \n",
    "    existing_data.append(data)\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(existing_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "async def scrape_attraction_details(new_tab, city, category_field, specific_type):\n",
    "    try:\n",
    "\n",
    "        # Name of the Attraction\n",
    "        name_locator = new_tab.locator('h1.biGQs._P.CIuBz')\n",
    "        await name_locator.wait_for(state=\"visible\", timeout=15000)\n",
    "        name = await name_locator.inner_text()\n",
    "\n",
    "        # Image Link\n",
    "        img_locator = new_tab.locator('picture.NhWcC._R.mdkdE.afQPz.eXZKw img').first\n",
    "        srcset = await img_locator.get_attribute(\"srcset\")\n",
    "        # Take the first URL in srcset or fallback to src\n",
    "        image_link = srcset.split(',')[0].split(' ')[0] if srcset else await img_locator.get_attribute(\"src\")\n",
    "        \n",
    "# 3. Scoped Operating Hours Logic\n",
    "        operating_hours = {}\n",
    "        \n",
    "        try:\n",
    "            # 1. Click the button using JS to bypass visibility checks\n",
    "            hours_btn = new_tab.locator('button.keqHA.f._S.G_.w').first\n",
    "            await hours_btn.evaluate(\"node => { node.scrollIntoView(); node.click(); }\")\n",
    "            \n",
    "            # 2. Wait for the container to be ATTACHED (it might be hidden initially)\n",
    "            container_selector = 'div[data-automation=\"attractionsPoiHoursForDay\"]'\n",
    "            container = new_tab.locator(container_selector).first\n",
    "            await container.wait_for(state=\"attached\", timeout=7000)\n",
    "            \n",
    "            # 3. Force the container to be visible via JS if needed\n",
    "            await container.evaluate(\"node => node.style.display = 'block'\")\n",
    "            \n",
    "            # 4. Wait specifically for the DAY elements inside to appear\n",
    "            day_locator = container.locator('div.biGQs._P.ezezH')\n",
    "            await day_locator.first.wait_for(state=\"visible\", timeout=5000)\n",
    "\n",
    "            # 5. Extract only from this specific container\n",
    "            days = await day_locator.all()\n",
    "            times = await container.locator('div.biGQs._P.VImYz.AWdfh').all()\n",
    "\n",
    "            for d, t in zip(days, times):\n",
    "                day_text = (await d.inner_text()).strip()\n",
    "                time_text = (await t.inner_text()).strip()\n",
    "                \n",
    "                # Knowledge Graph Validation\n",
    "                if any(day in day_text for day in [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]):\n",
    "                    operating_hours[day_text] = time_text\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Scoped hours extraction failed: {e}\")\n",
    "\n",
    "        print(f'Name: {name}, City: {city}, Image Link: {image_link}, Attraction Type: {category_field}, subcategory_specific_type: {specific_type}, operating hours: {operating_hours} ')\n",
    "        return {\n",
    "            \"name\": name,\n",
    "            \"city\": city,\n",
    "            \"image_link\": image_link,\n",
    "            \"attraction_type\": category_field,\n",
    "            \"subcategory_specific_type\": specific_type,\n",
    "            \"operating_hours\": operating_hours,\n",
    "            \"BudgetTier\": \"TBD\", # Placeholder for LLM pipeline\n",
    "            \"WeatherSuitability\": \"TBD\" # Placeholder for LLM pipeline\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting details: {e}\")\n",
    "        return None\n",
    "    \n",
    "def get_random_proxy(filepath=\"proxies.txt\"):\n",
    "    \"\"\"Reads the proxy file and returns a random valid proxy string.\"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"‚ö†Ô∏è {filepath} not found. Running without proxy.\")\n",
    "        return None\n",
    "        \n",
    "    with open(filepath, \"r\") as f:\n",
    "        # Load lines and strip whitespace\n",
    "        proxies = [line.strip() for line in f if line.strip()]\n",
    "        \n",
    "    # Filter out local/invalid proxies provided in your list\n",
    "    invalid_ips = [\"0.0.0.0\", \"127.0.0.7\"]\n",
    "    valid_proxies = [p for p in proxies if not any(ip in p for ip in invalid_ips)]\n",
    "    \n",
    "    if not valid_proxies:\n",
    "        return None\n",
    "        \n",
    "    proxy_addr = random.choice(valid_proxies)\n",
    "    print(f\"üåê Using proxy: {proxy_addr}\")\n",
    "    \n",
    "    # Camoufox expects a dictionary format for proxies\n",
    "    return {\n",
    "        \"server\": f\"http://{proxy_addr}\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd219efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è proxies.txt not found. Running without proxy.\n",
      "Checking for cookies on the page...\n",
      "Session state updated\n",
      "Processing: Sights & Landmarks\n",
      "Found 30 attractions in Sights & Landmarks\n",
      "Opening attraction 1: 1. Reichstag Building\n",
      "Could not click item 1: Locator.click: Target page, context or browser has been closed\n",
      "Call log:\n",
      "  - waiting for locator(\"div.XfVdV.o.AIbhI\").first\n",
      "    - locator resolved to <div class=\"XfVdV o AIbhI\">‚Ä¶</div>\n",
      "  - attempting click action\n",
      "    - waiting for element to be visible, enabled and stable\n",
      "    - element is visible, enabled and stable\n",
      "    - scrolling into view if needed\n",
      "    - done scrolling\n",
      "    - performing click action\n",
      "\n"
     ]
    },
    {
     "ename": "TargetClosedError",
     "evalue": "Locator.count: Target page, context or browser has been closed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTargetClosedError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 93\u001b[0m\n\u001b[1;32m     89\u001b[0m                         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPage \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnext_page_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found. Ending category early.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     90\u001b[0m                         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m run_scraper()\n",
      "Cell \u001b[0;32mIn[24], line 49\u001b[0m, in \u001b[0;36mrun_scraper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Take specific type: first subdiv in alPVI eNNhq PgLKC tnGGX yzLvM\u001b[39;00m\n\u001b[1;32m     48\u001b[0m type_locator \u001b[38;5;241m=\u001b[39m container\u001b[38;5;241m.\u001b[39mlocator(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv.alPVI.eNNhq.PgLKC.tnGGX.yzLvM div\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfirst\n\u001b[0;32m---> 49\u001b[0m specific_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m type_locator\u001b[38;5;241m.\u001b[39minner_text() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m type_locator\u001b[38;5;241m.\u001b[39mcount() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN/A\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m current_link \u001b[38;5;241m=\u001b[39m page\u001b[38;5;241m.\u001b[39mlocator(selector)\u001b[38;5;241m.\u001b[39mnth(i)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/playwright/async_api/_generated.py:16829\u001b[0m, in \u001b[0;36mLocator.count\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m  16810\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcount\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m  16811\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Locator.count\u001b[39;00m\n\u001b[1;32m  16812\u001b[0m \n\u001b[1;32m  16813\u001b[0m \u001b[38;5;124;03m    Returns the number of elements matching the locator.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  16826\u001b[0m \u001b[38;5;124;03m    int\u001b[39;00m\n\u001b[1;32m  16827\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m> 16829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping\u001b[38;5;241m.\u001b[39mfrom_maybe_impl(\u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl_obj\u001b[38;5;241m.\u001b[39mcount())\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/playwright/_impl/_locator.py:423\u001b[0m, in \u001b[0;36mLocator.count\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcount\u001b[39m(\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    422\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m--> 423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_frame\u001b[38;5;241m.\u001b[39m_query_count(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/playwright/_impl/_frame.py:136\u001b[0m, in \u001b[0;36mFrame._query_count\u001b[0;34m(self, selector)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_query_count\u001b[39m(\u001b[38;5;28mself\u001b[39m, selector: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqueryCount\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselector\u001b[39m\u001b[38;5;124m\"\u001b[39m: selector})\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/playwright/_impl/_connection.py:69\u001b[0m, in \u001b[0;36mChannel.send\u001b[0;34m(self, method, timeout_calculator, params, is_internal, title)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msend\u001b[39m(\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     63\u001b[0m     method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m     title: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     68\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mwrap_api_call(\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_send(method, timeout_calculator, params, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m     71\u001b[0m         is_internal,\n\u001b[1;32m     72\u001b[0m         title,\n\u001b[1;32m     73\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/playwright/_impl/_connection.py:559\u001b[0m, in \u001b[0;36mConnection.wrap_api_call\u001b[0;34m(self, cb, is_internal, title)\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m cb()\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m--> 559\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m rewrite_error(error, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparsed_st[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapiName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_zone\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mTargetClosedError\u001b[0m: Locator.count: Target page, context or browser has been closed"
     ]
    }
   ],
   "source": [
    "async def run_scraper():\n",
    "    \n",
    "    categories = [\"Sights & Landmarks\", \"Museums\", \"Nightlife\", \"Nature & Parks\"]\n",
    "    max_pages = 10\n",
    "    city = \"Berlin\"\n",
    "    selected_proxy = get_random_proxy(\"proxies.txt\")\n",
    "\n",
    "    async with AsyncCamoufox(\n",
    "        headless=False,\n",
    "        humanize=True, \n",
    "        os=\"windows\",\n",
    "        persistent_context=True, \n",
    "        user_data_dir=\"./tripadvisor_session_2026\",\n",
    "        proxy=selected_proxy,\n",
    "        exclude_addons=[DefaultAddons.UBO],\n",
    "        block_webgl=False,\n",
    "        main_world_eval=True,\n",
    "        disable_coop=True\n",
    "    ) as browser:\n",
    "        \n",
    "        page = await browser.new_page()\n",
    "        base_url = \"https://www.tripadvisor.com/Attractions-g187323-Activities-oa0-Berlin.html\"\n",
    "\n",
    "        await page.goto(base_url, wait_until=\"domcontentloaded\", timeout=60000)\n",
    "        await handle_cookies(page)\n",
    "        await page.context.storage_state(path=\"tripadvisor_auth.json\")\n",
    "        await asyncio.sleep(3)\n",
    "\n",
    "        print(\"Session state updated\")\n",
    "\n",
    "        for category_name in categories:\n",
    "            \n",
    "            print(f'Processing: {category_name}')\n",
    "\n",
    "            category_btn = page.get_by_text(category_name, exact=True).first\n",
    "            await category_btn.click()\n",
    "\n",
    "            for current_page_num in range(1, max_pages + 1):\n",
    "\n",
    "                selector = 'div.XfVdV.o.AIbhI'\n",
    "                count = await page.locator(selector).count()\n",
    "                print(f\"Found {count} attractions in {category_name}\")\n",
    "\n",
    "                for i in range(count):\n",
    "                    \n",
    "                    container = page.locator('div.hZuqH.y').nth(i)\n",
    "                    # Take specific type: first subdiv in alPVI eNNhq PgLKC tnGGX yzLvM\n",
    "                    type_locator = container.locator('div.alPVI.eNNhq.PgLKC.tnGGX.yzLvM div').first\n",
    "                    specific_type = await type_locator.inner_text() if await type_locator.count() > 0 else \"N/A\"\n",
    "\n",
    "                    current_link = page.locator(selector).nth(i)\n",
    "                    \n",
    "                    try:\n",
    "                        await current_link.scroll_into_view_if_needed()\n",
    "                        attraction_name = await current_link.text_content()\n",
    "                        print(f'Opening attraction {i+1}: {attraction_name.strip()}')\n",
    "\n",
    "                        async with page.expect_popup() as popup_info:\n",
    "                            await current_link.click()\n",
    "                        \n",
    "                        \n",
    "                        new_tab = await popup_info.value \n",
    "     \n",
    "\n",
    "            \n",
    "                        data = await scrape_attraction_details(new_tab, city, category_name, specific_type)\n",
    "                        \n",
    "                        if data:\n",
    "                            save_to_json(data)\n",
    "                            print(f\"‚úÖ Saved data for {attraction_name.strip()}\")\n",
    "\n",
    "                        await new_tab.close()\n",
    "                        \n",
    "                        await asyncio.sleep(random.uniform(1, 2))\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Could not click item {i+1}: {e}\")\n",
    "                        continue\n",
    "                \n",
    "                if current_page_num < max_pages:\n",
    "                    next_page_num = current_page_num + 1\n",
    "                    next_btn_selector = f'div.Yzhnw.P [aria-label=\"{next_page_num}\"]'\n",
    "                    next_btn = page.locator(next_btn_selector)\n",
    "\n",
    "                    if await next_btn.count() > 0:\n",
    "                        await next_btn.scroll_into_view_if_needed()\n",
    "                        await next_btn.click()\n",
    "                    else:\n",
    "                        print(f\"Page {next_page_num} not found. Ending category early.\")\n",
    "                        break\n",
    "\n",
    "\n",
    "await run_scraper()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
